\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[section]{algorithm}
\usepackage[fontset=ubuntu]{ctex}
\usepackage{epsfig,subfigure}
\usepackage{array}
\usepackage{multirow}
\newcommand{\minitab}[2][c]{\begin{tabular}{#1}#2\end{tabular}}

\floatname{algorithm}{算法}
\renewcommand{\algorithmicrequire}{\textbf{输入：}}
\renewcommand{\algorithmicensure}{\textbf{输出：}}
\renewcommand{\algorithmiccomment}[1]{\hfill /* #1 */}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{
Towards Read-Optimized Key-value Store on Flash Storage
}

\author{\IEEEauthorblockN{Shangyu Wu$^{1}$, Yi Wang$^{1}$, Amelie Chi Zhou$^{1}$, Rui Mao$^{1}$, Zili Shao$^{2}$, Tao Li$^{3}$}
\IEEEauthorblockA{\textit{1. The National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen, China} \\
\textit{2. Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China}\\
\textit{3. Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA.}\\
shangyuwu1006@gmail.com, \{yiwang, chi.zhou, mao\}@szu.edu.cn, shao@cse.cuhk.edu.hk, taoli@ece.ufl.edu}
}

\maketitle

%\renewcommand{\baselinestretch}{0.95}

\begin{abstract}
%\input{0-abs}

数据的

Deep convolutional neural networks have become the mainstream
solution for many artificial intelligence applications.
However, they are still rarely deployed on mobile or edge devices
due to the cost of a substantial amount of data movement
among limited resources.
The emerging processing-in-memory neuromorphic architecture
offers a promising direction
to accelerate the inference process.
%of convolutional neural networks.
The key issue becomes how to effectively allocate
the processing of inference between computing and storage resources
%for mobile edge computing.
on an edge device.

本文提出 \emph{Bi-LSMTree}, 一种能够上浮伸展的LSM-Tree结构，
a resource allocation scheme to accelerate the \emph{\underline{I}}nference process on
\emph{\underline{Mobile}} or edge devices.
Mobile-I targets at the emerging 3D neuromorphic architecture
to reduce the processing latency among computing resources
and fully utilize the limited on-chip storage resources.
We formulate the target problem as a resource allocation problem
and use a software-based solution to offer the cross-platform deployment
across multiple mobile or edge devices.
We conduct a set of experiments using realistic workloads
that are generated from Intel Movidius neural compute stick.
Experimental results show that Mobile-I
can effectively reduce the processing latency
and improve the utilization of computing resources
with negligible overhead in comparison
with representative schemes.


\end{abstract}

\begin{IEEEkeywords}
Key-value store, LSM-Tree, floating, 
\end{IEEEkeywords}


%``Fig.~\ref{fig}'', even at the beginning of a sentence.

%\begin{table}[htbp]
%\caption{Table Type Styles}
%\begin{center}
%\begin{tabular}{|c|c|c|c|}
%\hline
%\textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
%\cline{2-4}
%\textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
%\hline
%copy& More table copy$^{\mathrm{a}}$& &  \\
%\hline
%\multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%\end{tabular}
%\label{tab1}
%\end{center}
%\end{table}

%\begin{figure}[htbp]
%\centerline{\includegraphics{fig1.png}}
%\caption{Example of a figure caption.}
%\label{fig}
%\end{figure}

%For example, write ``Temperature (K)'', not ``Temperature/K''.


%\renewcommand{\baselinestretch}{0.93}
%\input{1-intro}
%\input{2-background}
%\input{3-technique}
%\input{5-exp}
%%\input{6-related}
%\input{7-conclusion}

%\renewcommand{\baselinestretch}{0.93}

%\bibliographystyle{ACM-Reference-Format}
%\bibliographystyle{abbrv}
%

\input{1-intro}
\input{2-model}
\input{6-floating}
\input{7-exp}
\input{5-conclusion}

\section*{Acknowledgment}

This work was supported in part by the National
Natural Science Foundation of China (61502309
and 61802260),
in part by the Guangdong Natural Science Foundation
(2016A030313045, 2018A030310440, and 2017B030314073),
in part by the Shenzhen Science and Technology Foundation
(JCYJ20170817100300603,
JCYJ20170816093943197,
and JCYJ20170302153955969),
in part by the Research Grants Council of the Hong Kong Special Administrative Region, China
(GRF 15222315, GRF 15273616, GRF 15206617, and GRF 15224918),
in part by Direct Grant for Research, The Chinese University of Hong Kong (Project No. 4055096),
in part by the
Guangdong Pre-national Project (2014GKXM054),
and in part by the Natural Science Foundation of
SZU (803/000027060147). Yi Wang is the corresponding author.
%,
%and in part by the State Key Laboratory of Computer Architecture,
%Institute of Computing Technology, Chinese Academy of Science (CARCH201608).
%Yi Wang and Rui Mao are corresponding authors.



\bibliographystyle{IEEEtran}
\bibliography{ref}
%\bibliographystyle{IEEEtran}
%\bibliography{ref}

\end{document}
